Abstract. The paper introduces a quick-witted system that assists em-ployers to ﬁnd the right candidate for a job and vice-versa. Multipleapproaches have to be taken into account for parsing, analyzing, andscoring documents (CV, Vanancy details). However, In this paper wehave devised an approach for ranking such documents using word2vec al-gorithm and matching them to their appropriate pair using Gale-Shapleyalgorithm. When ranking a CV, diﬀerent cases are taken into consider-ation: skills, experience, education, location. The ranks are then used toﬁnd an appropriate match of employers and employees with the use ofGale-Shapley algorithm which eases companies for higher best possiblecandidates. The methods experimented for the scoring and matching isexplained below on the paper.Keywords: Natural Language Processing, NER, word2vec, Gale Shap-ley, CBOW, word embedding, Cosine similarity1 IntroductionTo hire an employee, CVs are screened manually by the HR and based on thequaliﬁcations the certain persons are hired. This system has been running for along time. After the advancement in Natural Language Processing, CV parsinghas become an integral part of it. Furthermore, if the CV can be judged similarto the human judgement then it would be a more sophisticated system. As thesystem can process and manipulate large CVs in a short period of time. This
2 S. Pudasaini et al.paper describes a method to identify the standard of the CV and match thembased on the requirements of a certain company.So, the scoring model has been proposed in this paper to provide a scoreto the CV. Several criteria have been displayed to provide the score to theCV. The designation of the job seeker, progress score, location, skills and scoreplays vital roles in scoring of the CV. These factors were selected after severalexperiments and suitable conditions have been applied. Similarly, to make iteasier for job providers and seekers to ﬁnd the best match among themselves theGale-Shapley is in action. It helps to ﬁnd the best pair among the both parties.As this algorithm has been used for ﬁnding pairs for marriage this paper aimsto use it for pairing of employees with employers and vice versa.2 Literature ReviewDocument ranking or comparing the similarity between the documents has beenidentiﬁed as one of the major tasks in the Natural Language Processing relatedactivities. Diﬀerent measures with diﬀerent ideas have been implemented forgetting a better result. In the paper [1] the author has focused on measuringthe similarity between sentences. The paper shows that even though word2vecand cosine similarity gives appropriate results, it is still possible to improvethe similarity result of the sentences by combining the word embeddings withthe hand-engineered features. Similarly, on the paper titled as [2] shows theway of making online recruitment more eﬃcient and eﬀective. The paper [3]shows the way for recruiters to ﬁnd the appropriate candidate by their skillsusing word2vec algorithm. The skills were extracted from vancacy details andclassiﬁed according to the vancacy details with the same content. Then it wastrained on the word2vec algorithm. The paper [4] deﬁnes a way of hiring using thecombination of word embeddings and NER model. [5] is a system for personalityevaluation and CV analysis where users have to manually ﬁll up the form, giveaptitude tests and upload their CV on the website. The evaluation is done on thereference to Machine Learning algorithms. [6] proposes many methods to solvethe problem of proﬁling applications according to a speciﬁc work oﬀer, basedon vectorial and probabilistic models. Their target is a framework capable ofreproducing the recruitment consultant’s judgment. By using ROC curves, wehave evaluated a number of similarity measures to rank candidates.The paper [7] matches the employee with the oﬀered position based on theirqualiﬁcation with the use of Gale Shapley algorithm. [8] also puts a new way forcreating a social network and matching of the jobs with the use of Gale Shapleyalgorithm. [9] describes a procedure to screen and match the CV with proﬁles,skills and other features available in the CV with clustering algorithms. Thematching model were made from 2283 CVs and job requirements.
Title Suppressed Due to Excessive Length 33 Methods3.1 ScoringTo perform scoring between two documents, we have proposed the followingapproaches: -•Scoring of description with multiple CV•Scoring of one CV with multiple vancacy details•Scoring of CV content with vancacy details contentBefore getting into these approaches, we will discuss two techniques that we haveimplemented in getting our result. They are: -Word Embedding using Word2Vec AlgorithmTo match the CV with vancacy details, we have used the help of word em-beddings, which is just the numerical representation of words in the form ofvectors. Word embeddings have been proven to be very eﬀective when workingwith textual data in the ﬁeld of Natural Language Processing.Here, we have implemented the word2vec model which implements the NeuralNetwork architecture for generating the word embeddings of the documents [10]and has been providing the state-of-the-art word embeddings results. The embed-ding vectors that we receive from the word2vec model is a dense one. Whereas,other embedding approaches like one hot encoding gives a sparse vector as itsresult. In the context of capturing the relation between diﬀerent words, densevectors give a better result than the sparse vector [11]. And as we want to cap-ture the relationship between the words, word embedding using word2vec modelwas the appropriate choice for us.A word2vec model can be generated with two diﬀerent approaches: -•Skip-gram•CBOW (Common Bag of Words)The functionality of the skip-gram model is that it takes a certain word andtries to predict its surrounding word or context words. Whereas in CBOW, ittakes the context and predicts the target word.The word2vec model is trained with a data corpus comprising 12,000 CVsusing the CBOW model.Measuring SimilarityTo perform the text similarity, there are 3 diﬀerent approaches i.e. string based,corpus based and knowledge based. Here, we will be following the string basedsimilarity approach, where we measure how similar or dissimilar a pair of stringsare. [12]In the string based similarity method, similarity can be measured using var-ious approaches like cosine similarity, dice’s similarity, euclidean distance and
4 S. Pudasaini et al.Fig. 1. Neural Network architecture of CBOW and Skip-gram Modeljaccard similarity. Among them, cosine similarity is the one which is frequentlyused for measuring the distance between the two given vectors in a vector space.cos(θ) = ABkAkkBk=Pni=1 AiBi√Pni=1 (Ai)2√Pni=1 (Bi)2If the pair of strings are close to each other, then we will get a value of θsmaller (closer to 0) giving us the output value closer to 1. And if the strings arenot closely related to each other, the value of θwill be higher giving the outputvalue closer to 0.Scoring of one vancacy details with multiple CVThis scoring module is used when a score for vancacy details is required incomparison to multiple CVs.The result we receive is of a json type, having two keywords i.e. “user proﬁles”and ‘job’. The keyword “user proﬁles” holds the record of multiple CVs thatincludes their id, personal information, experience details and technical and softskills details. The other keyword ‘job’ holds the information of the vancacy detailsIt includes its id, job title, vancacy details and location.The score which is generated from the model, is based on multiple entities(condition). Each entity holds a certain weightage that has been assigned to itafter appropriate testing. Higher the score, higher similarity between the vancacydetails and CV. The entity along with their respective weightages are: -
Title Suppressed Due to Excessive Length 5Fig. 2. most similar tokens of a given word
6 S. Pudasaini et al.Scoring entity DescriptionSkills Score 25Experience Score 15Designation Score 40Distance Score 5Progress Score 15Total Score 100In the scoring function, the skill sets are used to calculate the skills score.And the locations are used to calculate the distance score. The nearer the CVslocation, higher the score. Likewise for scoring the designation, the system checksif the job-title is provided on the json and the designation from the job-contentis parsed using the custom trained NER tagger then added together to form adesignations list. The system checks if any values in user-designation and thejob designation list match and if they do the score is generated.The procedure of scoring on the basis of “Progress score” is quite diﬀer-ent from the others.It ﬁrst visualizes the ‘designations’ and ‘designation dates’graphically and calculates the slope of the graph. Working on this method wegot to know about the priority of categorizing a designation as per its hierar-chy. However there wasn’t any predeﬁned way to do this. So, we created a rulebased ﬁle parsing method which takes a ﬁle containing every possible designationand categorizes them into Junior Employee, Senior Employee, Intermediate Em-ployee or Manager. This normalizes the designation and the relevant slope canbe calculated. The slope provides the stability of candidates for the designations.Scoring of one CV with vancacy details contentOne of the major diﬀerences between this scoring approach and the other pre-vious approaches is that here we do not parse the documents. The CV contentsand vancacy details contents are preprocessed with steps such as text cleaning,stopwords removal, lemmatization and so on. Then the ﬁltered tokens from theCV and vancacy details are passed to the custom trained Word2Vec model. Eval-uation of word embeddings of every token is performed and the mean embeddingrepresenting whole textual content is calculated. After getting the mean embed-ding from both CV and vancacy details, cosine distance similarity is applied tocalculate the similarity score.3.2 Matching using Gale Shapley AlgorithmAfter the completion of generating scores for the required document, we use thosescores for recommending appropriate CVs to any given job-descriptions and vice-versa using an accredited pairing algorithm called “Gale Shapley” which wasdevised by David Gale and Llyod Shapley in 1962. This algorithm is capableof solving any pairing problems across the world like students choosing bestuniversities in online educational platforms or women looking for men and vice-versa in dating sites and connecting users to an internet service in the smallestamount of time. In all of these cases, we are required to create a stable set of
Title Suppressed Due to Excessive Length 7Fig. 3. Flow diagram of the designation scoring model
8 S. Pudasaini et al.pairs that needs to satisfy a given criteria. Theoretically, a stable pair is formedwhen a pair (A, B) has no better options than each other.We made use of the proposed pseudocode for the stable marriage problem,to solve the pairing problem in our system. Like in the proven example of stablemarriage, we have two sets of pairs in our system, CV and job-descriptions. Andeach element has to ﬁnd the best candidate on the other set, i.e. ﬁnding thebest candidate for a given company or ﬁnding the best company for any givencandidate.These two sets of data are acquired as a json ﬁle in our system. With akeyword representing its respective section. The ﬁrst keyword holds the data foreach job-description with its respective score for each CV. This score is providedby the scoring endpoint that scores one job-description with multiple CV.Fig. 4. json representation of one jd and multiple CVSimilarly, the other keyword holds the data for each CV with its respectivescore for each job-description. This score is manually provided by the user tothe respective job-description.Fig. 5. json representation of one CV and multiple jdValues in both of these sets are ordered in the descending order, i.e. the mostpreferred CV or jd is at ﬁrst. However, this data represents more than one stableset of arrangements. And this is where we make use of the algorithm that laterprovides a single set of arrangement for each CV or job-description.
Title Suppressed Due to Excessive Length 9Fig. 6. Stable set of arrangement of CV and job-description4 Conclusion and Future WorksIn this paper, the word2vec algorithm using CBOW model is implemented forcreating the required embedding vectors and the cosine similarity for measur-ing the similarity score between CV and vancacy details. There are various ap-proaches to generate such word embeddings like skip-gram model, TF IDF modeland so on. However, the custom Word2Vec model trained on our custom dataproduced highly relevant results. Google pretrained Word2Vec model was alsoused for generating such word embeddings. However, a more accurate result wasobtained by training such a custom Word2Vec model. The word2vec model forthe algorithm was created using the Gensim library which was trained on 1220documents consisting of CV and vancacy details. The result obtained on the testdata for the scoring reﬂected a satisfactory result. While measuring the similarityof tokens, sentences or documents using the cosine similarity gave better resultsthan other methods. Such better results were obtained due to the contextualawareness of such trained custom Word2Vec models.The word2vec model could be replaced by other powerful embedding moldessuch as ELMO, BERT etc. Such method can give better result than the currentone. The data for creating the word embeddings can also be increased to getbetter result